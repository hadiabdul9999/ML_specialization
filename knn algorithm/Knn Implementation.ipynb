{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Classifying customers to help grow new accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   CFS has secured several new major accounts -- companies which previously purchased only from their competitors, including those old-time financial service bastions in Manhattan. The bad news is that these new customers are only purchasing one or two of their products, instead of the wide array of products they sell to their more established customers. In fact, revenue from their newly acquired customers is only about one-tenth that of their older wholesale customers.\n",
    "   To grow new accounts, they need to know which products are most appropriate to sell to which new customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin working with the customers data, we'll first need to import the functionality we need, and load our data into a pandas DataFrame.\n",
    "Run the code cell below to load our data and display the first few entries (customers) for examination using the .head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type     LifeStyle  Vacation  eCredit  salary  property label\n",
      "0  student  spend>saving         6       40   13.62    3.2804    C1\n",
      "1  student  spend>saving        11       21   15.32    2.0232    C1\n",
      "2  student  spend>saving         7       64   16.55    3.1202    C1\n",
      "3  student  spend>saving         3       47   15.71    3.4022    C1\n",
      "4  student  spend>saving        15       10   16.96    2.2825    C1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdul/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "names=['Type','LifeStyle','Vacation','eCredit','salary','property','label']\n",
    "train_data=pd.read_csv(\"training.txt\",header=None,names=names)\n",
    "test_data=pd.read_csv(\"testing.txt\",header=None,names=names)\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a sample of the customers data, we can see the various features present for each customer:\n",
    "    \n",
    "    -> Type:{student,engineer,librarian,professor,doctor} - The type of customer.\n",
    "    \n",
    "    -> LifeStyle:{spend << saving,spend < saving,spend > saving,spend >> saving} - The comparision of money spent and money saved by the customer.\n",
    "    \n",
    "    -> Vacation: A real number depicting the number of vacations a customer has taken.\n",
    "    \n",
    "    -> eCredit: A real number depicting the eCredit of a customer.\n",
    "    \n",
    "    -> salary: A real number depicting the salary of a customer.\n",
    "    \n",
    "    -> property: A real number depicting the property worth of a customer.\n",
    "    \n",
    "    -> label:{C1,C2,C3,C4,C5} - The class that defines the customer.\n",
    "Since we're interested in the outcome of label for each customer, we can remove the label feature from this dataset and store it as its own separate variable labels. We will use these labels later as our prediction targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the numeric attributes(Vacation,eCredit,salary,property) to fall between 0 and 1 using the Min Max normalization.\n",
    "The function below takes an array as argument and returns an array with normalized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_Vacation=np.min(train_data['Vacation'])\n",
    "max_Vacation=np.max(train_data['Vacation'])\n",
    "min_eCredit=np.min(train_data['eCredit'])\n",
    "max_eCredit=np.max(train_data['eCredit'])\n",
    "min_salary=np.min(train_data['salary'])\n",
    "max_salary=np.max(train_data['salary'])\n",
    "min_property=np.min(train_data['property'])\n",
    "max_property=np.max(train_data['property'])\n",
    "def normalized(arr):\n",
    "    array=[]\n",
    "    max_value=np.max(arr)\n",
    "    min_value=np.min(arr)\n",
    "    for x in arr:\n",
    "        x_normalized=(x-min_value)/float((max_value-min_value))\n",
    "        array.append(x_normalized)\n",
    "    return  array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.079365079365079361, 0.15873015873015872, 0.095238095238095233, 0.031746031746031744, 0.22222222222222221]\n"
     ]
    }
   ],
   "source": [
    "normalized_Vacation=normalized(train_data['Vacation'])\n",
    "normalized_eCredit=normalized(train_data['eCredit'])\n",
    "normalized_salary=normalized(train_data['salary'])\n",
    "normalized_property=normalized(train_data['property'])\n",
    "print normalized_Vacation[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to replace the training set data with the new normalized data. So we normalize each column seperately and replace the training data set values with the new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type     LifeStyle  Vacation   eCredit    salary  property label\n",
      "0  student  spend>saving  0.079365  0.107558  0.219960  0.183167    C1\n",
      "1  student  spend>saving  0.158730  0.052326  0.293102  0.112797    C1\n",
      "2  student  spend>saving  0.095238  0.177326  0.346023  0.174200    C1\n",
      "3  student  spend>saving  0.031746  0.127907  0.309882  0.189984    C1\n",
      "4  student  spend>saving  0.222222  0.020349  0.363663  0.127311    C1\n"
     ]
    }
   ],
   "source": [
    "train_data['Vacation']=normalized_Vacation\n",
    "train_data['eCredit']=normalized_eCredit\n",
    "train_data['salary']=normalized_salary\n",
    "train_data['property']=normalized_property\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding distances between floating point numbers is possible but it is not possible for strings unless the strings are converted to numbers. We have been provided with a similarity matrix using which we will find out similarity between two strings. The following function sim takes in two strings and returns the similarity value between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type     LifeStyle  Vacation   eCredit    salary  property label\n",
      "0  student  spend>saving  0.079365  0.107558  0.219960  0.183167    C1\n",
      "1  student  spend>saving  0.158730  0.052326  0.293102  0.112797    C1\n",
      "2  student  spend>saving  0.095238  0.177326  0.346023  0.174200    C1\n",
      "3  student  spend>saving  0.031746  0.127907  0.309882  0.189984    C1\n",
      "4  student  spend>saving  0.222222  0.020349  0.363663  0.127311    C1\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "workbook = xlrd.open_workbook('similaritymatrix.xls')\n",
    "def sim(x,y):\n",
    "    dict1={'student':1,'engineer':2,'librarian':3,'professor':4,'doctor':5}\n",
    "    dict2={'spend<<saving':1,'spend<saving':2,'spend>saving':3,'spend>>saving':4}\n",
    "    if(x in dict1.keys()):\n",
    "        worksheet=workbook.sheet_by_index(0)\n",
    "        return worksheet.cell(dict1[x],dict1[y]).value\n",
    "    else:\n",
    "        worksheet=workbook.sheet_by_index(2)\n",
    "        return worksheet.cell(dict2[x],dict2[y]).value\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row from the testing data set is compared against all rows from the training data and distances are calculated and put in the distances array. As k=3 we take the top3 values that have the greatest score compared to the test data row. In the end collective scores of each class is calculated and whichever turns out to be the maximum is the predicted class. This process is carried out for all the rows in testing data set and all the predicted labels are put into the predicted array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"\n",
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n",
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C1', 'C1', 'C1', 'C2', 'C2', 'C2', 'C2', 'C3', 'C3', 'C3', 'C3', 'C5', 'C4', 'C1', 'C4', 'C4', 'C4', 'C5', 'C5', 'C5']\n"
     ]
    }
   ],
   "source": [
    "labels=test_data['label']\n",
    "features = test_data.drop('label', axis = 1)\n",
    "predicted=[]\n",
    "for i in features.index:\n",
    "    features_vector=features.ix[i]\n",
    "    distances=[]\n",
    "    for j in train_data.index:\n",
    "        train_data_vector=train_data.ix[j]\n",
    "\n",
    "        type_value=1-sim(train_data_vector['Type'],features_vector['Type'])\n",
    "\n",
    "        LifeStyle_value =1-sim(train_data_vector['LifeStyle'],features_vector['LifeStyle'])\n",
    "\n",
    "        Vacation_normalized=(features_vector['Vacation']-min_Vacation)/float((max_Vacation-min_Vacation))\n",
    "        Vacation_value=np.power(train_data_vector['Vacation']-Vacation_normalized,2)\n",
    "\n",
    "        eCredit_normalized=(features_vector['eCredit']-min_eCredit)/float((max_eCredit-min_eCredit))\n",
    "        eCredit_value=np.power(train_data_vector['eCredit']-eCredit_normalized,2)\n",
    "\n",
    "        salary_normalized=(features_vector['salary']-min_salary)/float((max_salary-min_salary))\n",
    "        salary_value=np.power(train_data_vector['salary']-salary_normalized,2)\n",
    "\n",
    "        property_normalized=(features_vector['property']-min_property)/float((max_property-min_property))\n",
    "        property_value=np.power(train_data_vector['property']-property_normalized,2)\n",
    "\n",
    "        similarity=1/np.sqrt(type_value+LifeStyle_value+Vacation_value+eCredit_value+salary_value+property_value)\n",
    "        distances.append((similarity,train_data_vector['label']))\n",
    "    Top3=sorted(distances,key=lambda x: x[0])[-3:]\n",
    "    C1=0\n",
    "    C2=0\n",
    "    C3=0\n",
    "    C4=0\n",
    "    C5=0\n",
    "    predicted_label=\"None\"\n",
    "    for dist,clas in Top3:\n",
    "        if(clas=='C1'):\n",
    "            C1=C1+dist\n",
    "        elif(clas=='C2'):\n",
    "            C2=C2+dist\n",
    "        elif(clas=='C3'):\n",
    "            C3=C3+dist\n",
    "        elif(clas=='C4'):\n",
    "            C4=C4+dist\n",
    "        else:\n",
    "            C5=C5+dist\n",
    "    if(C1>C2 and C1>C3 and C1>C4 and C1>C5):\n",
    "        predicted_label=\"C1\"\n",
    "    elif(C2>C1 and C2>C3 and C2>C4 and C2>C5):\n",
    "        predicted_label=\"C2\"\n",
    "    elif(C3>C1 and C3>C2 and C3>C4 and C3>C5):\n",
    "        predicted_label=\"C3\"\n",
    "    elif(C4>C1 and C4>C2 and C4>C3 and C4>C5):\n",
    "        predicted_label=\"C4\"\n",
    "    elif(C5>C1 and C5>C2 and C5>C3 and C5>C4):\n",
    "        predicted_label=\"C5\"\n",
    "    predicted.append(predicted_label)\n",
    "print predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have an accuracy of 23.81%.\n"
     ]
    }
   ],
   "source": [
    "def accuracy_score(truth, pred):\n",
    "    \"\"\" Returns accuracy score for input truth and predictions. \"\"\"\n",
    "    \n",
    "    # Ensure that the number of predictions matches number of outcomes\n",
    "    if len(truth) == len(pred): \n",
    "        \n",
    "        # Calculate and return the accuracy as a percent\n",
    "        return \"Predictions have an accuracy of {:.2f}%.\".format((truth == pred).mean()*100)\n",
    "    \n",
    "    else:\n",
    "        return \"Number of predictions does not match number of outcomes!\"\n",
    "print accuracy_score(labels,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are 23.81% accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type  LifeStyle  Vacation   eCredit    salary  property\n",
      "0     1          3  0.079365  0.107558  0.219960  0.183167\n",
      "1     1          3  0.158730  0.052326  0.293102  0.112797\n",
      "2     1          3  0.095238  0.177326  0.346023  0.174200\n",
      "3     1          3  0.031746  0.127907  0.309882  0.189984\n",
      "4     1          3  0.222222  0.020349  0.363663  0.127311\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "           metric=<function myfunc at 0x7facd03e46e0>, metric_params=None,\n",
       "           n_jobs=1, n_neighbors=5, p=2, weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def myfunc(x,y):\n",
    "    sc=0\n",
    "    for f,b in zip(x,y):\n",
    "        sc=sc+(f-b)**2\n",
    "    return 1/np.sqrt(sc)\n",
    "\n",
    "\n",
    "\n",
    "y_train=train_data['label']\n",
    "x_train=train_data.drop('label',axis=1)\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5, weights='uniform', algorithm='auto', metric=myfunc)\n",
    "x_train['Type']=x_train['Type'].map({'student':1,'engineer':2,'librarian':3,'professor':4,'doctor':5})\n",
    "x_train['LifeStyle']=x_train['LifeStyle'].map({'spend<<saving':1,'spend<saving':2,'spend>saving':3,'spend>>saving':4})\n",
    "ind=0\n",
    "Y_train=[]\n",
    "for x in y_train:\n",
    "    if(x==\"C1\"):\n",
    "        Y_train.append(1)\n",
    "    elif(x==\"C2\"):\n",
    "        Y_train.append(2)\n",
    "    elif(x==\"C3\"):\n",
    "        Y_train.append(3)\n",
    "    elif(x==\"C4\"):\n",
    "        Y_train.append(4)\n",
    "    elif(x==\"C5\"):\n",
    "        Y_train.append(5)\n",
    "    ind=ind+1\n",
    "print x_train.head()\n",
    "print Y_train\n",
    "neigh.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/abdul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Type      LifeStyle  Vacation   eCredit    salary  property\n",
      "0    student   spend<saving  0.174603  0.046512  0.571043  0.115417\n",
      "1    student  spend>>saving  0.444444  0.020349  0.571043  0.115417\n",
      "2    student  spend<<saving  0.428571  0.165698  0.571043  0.115417\n",
      "3   engineer   spend>saving  0.222222  0.110465  0.571043  0.115417\n",
      "4  librarian   spend<saving  0.015873  0.017442  0.571043  0.115417\n"
     ]
    }
   ],
   "source": [
    "x_test=features\n",
    "for i in x_test.index:\n",
    "    test_vector=x_test.ix[i]\n",
    "    test_vector['Vacation']=(test_vector['Vacation']-min_Vacation)/float((max_Vacation-min_Vacation))\n",
    "\n",
    "    test_vector['eCredit']=(test_vector['eCredit']-min_eCredit)/float((max_eCredit-min_eCredit))\n",
    "\n",
    "    test_vector['salary']=(features_vector['salary']-min_salary)/float((max_salary-min_salary))\n",
    "\n",
    "    test_vector['property']=(features_vector['property']-min_property)/float((max_property-min_property))\n",
    "    x_test.ix[i]=test_vector\n",
    "print x_test.head()\n",
    "x_test['Type']=x_test['Type'].map({'student':1,'engineer':2,'librarian':3,'professor':4,'doctor':5})\n",
    "x_test['LifeStyle']=x_test['LifeStyle'].map({'spend<<saving':1,'spend<saving':2,'spend>saving':3,'spend>>saving':4})\n",
    "y_pred = neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 1 1 1 1 3 3 1 1 1 1 3 3 1 1 1 3 3]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions have an accuracy of 52.38%.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_pred\n",
    "index=0\n",
    "lab=[]\n",
    "for x in labels:\n",
    "    if(x==\"C1\"):\n",
    "        lab.append(1)\n",
    "    elif(x==\"C2\"):\n",
    "        lab.append(2)\n",
    "    elif(x==\"C3\"):\n",
    "        lab.append(3)\n",
    "    elif(x==\"C4\"):\n",
    "        lab.append(4)\n",
    "    elif(x==\"C5\"):\n",
    "        lab.append(5)\n",
    "    index=index+1\n",
    "print lab\n",
    "accuracy_score(lab,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The predefined knn by scikit gives 52.38% accuracy when feeded with \"non-string\" inputs and using inverse euclidean formula to calculate distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
